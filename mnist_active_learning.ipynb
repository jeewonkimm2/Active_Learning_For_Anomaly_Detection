{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, SubsetRandomSampler, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define transforms for dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define initial labeled dataset\n",
    "num_initial_samples = 1000\n",
    "labeled_indices = torch.randperm(len(train_dataset))[:num_initial_samples]\n",
    "labeled_dataset = torch.utils.data.Subset(train_dataset, labeled_indices)\n",
    "\n",
    "# Define unlabeled dataset\n",
    "# unlabeled_indices = torch.arange(len(train_dataset))[~torch.isin(torch.arange(len(train_dataset)), labeled_indices)]\n",
    "# unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
    "unlabeled_indices = torch.arange(len(train_dataset))[~torch.eq(torch.arange(len(train_dataset)).unsqueeze(1), labeled_indices).any(1)]\n",
    "unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "\n",
    "# Define data loaders\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Define ResNet model\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18.conv1(x)\n",
    "        x = self.resnet18.bn1(x)\n",
    "        x = self.resnet18.relu(x)\n",
    "        x = self.resnet18.maxpool(x)\n",
    "\n",
    "        x = self.resnet18.layer1(x)\n",
    "        x = self.resnet18.layer2(x)\n",
    "        x = self.resnet18.layer3(x)\n",
    "        x = self.resnet18.layer4(x)\n",
    "\n",
    "        x = self.resnet18.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = ResNet18(num_classes=10)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train function\n",
    "def train(model, optimizer, labeled_loader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total = 0\n",
    "    for images, labels in labeled_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        train_acc += (predicted == labels).sum().item()\n",
    "    train_loss /= len(labeled_loader)\n",
    "    train_acc /= total\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query number: 1\n",
      "Train Loss: 0.3774, Train Accuracy: 0.9090\n",
      "Test Loss: 0.2743, Test Accuracy: 0.9296\n",
      "Query number: 2\n",
      "Train Loss: 0.2224, Train Accuracy: 0.9424\n",
      "Test Loss: 0.2172, Test Accuracy: 0.9492\n",
      "Query number: 3\n",
      "Train Loss: 0.3087, Train Accuracy: 0.9353\n",
      "Test Loss: 0.2801, Test Accuracy: 0.9289\n",
      "Query number: 4\n",
      "Train Loss: 0.2488, Train Accuracy: 0.9413\n",
      "Test Loss: 0.2396, Test Accuracy: 0.9452\n",
      "Query number: 5\n",
      "Train Loss: 0.2781, Train Accuracy: 0.9371\n",
      "Test Loss: 0.2326, Test Accuracy: 0.9402\n",
      "Query number: 6\n",
      "Train Loss: 0.2036, Train Accuracy: 0.9475\n",
      "Test Loss: 0.2262, Test Accuracy: 0.9492\n",
      "Query number: 7\n",
      "Train Loss: 0.3066, Train Accuracy: 0.9356\n",
      "Test Loss: 0.2141, Test Accuracy: 0.9498\n",
      "Query number: 8\n",
      "Train Loss: 0.1741, Train Accuracy: 0.9538\n",
      "Test Loss: 0.1824, Test Accuracy: 0.9566\n",
      "Query number: 9\n",
      "Train Loss: 0.1664, Train Accuracy: 0.9601\n",
      "Test Loss: 0.1720, Test Accuracy: 0.9601\n",
      "Query number: 10\n",
      "Train Loss: 0.1217, Train Accuracy: 0.9711\n",
      "Test Loss: 0.1705, Test Accuracy: 0.9573\n"
     ]
    }
   ],
   "source": [
    "# Active learning loop\n",
    "num_queries = 10\n",
    "batch_size = 32\n",
    "\n",
    "for query in range(num_queries):\n",
    "    print(\"Query number:\", query+1)\n",
    "    \n",
    "    # Train model on labeled dataset\n",
    "    train_loss, train_acc = train(model, optimizer, labeled_loader)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Evaluate model on test dataset\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            test_acc += (predicted == labels).sum().item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= total\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Make model predictions on unlabeled dataset\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in unlabeled_loader:\n",
    "            output = model(images)\n",
    "            predictions.append(output)\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "    # Select samples to label using entropy-based method\n",
    "    entropy = -torch.sum(torch.softmax(predictions, dim=1) * torch.log(torch.softmax(predictions, dim=1)), dim=1)\n",
    "    _, idx = torch.topk(entropy, k=batch_size)\n",
    "    labeled_indices = torch.cat([labeled_indices, unlabeled_indices[idx]])\n",
    "    unlabeled_indices = unlabeled_indices[~torch.eq(unlabeled_indices.unsqueeze(1), unlabeled_indices[idx]).any(1)]\n",
    "    \n",
    "    # Update labeled and unlabeled datasets\n",
    "    labeled_dataset = torch.utils.data.Subset(train_dataset, labeled_indices)\n",
    "    unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "    # Update labeled and unlabeled data loaders\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwanaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b1005dccb15e22d240b273f9fc181733100900e693183dab09dcac13af140a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
