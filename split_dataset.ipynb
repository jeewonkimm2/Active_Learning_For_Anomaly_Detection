{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [데이터 분할을 위한 폴더 생성]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = '/home/iai/Desktop/bsh/active_learning/data/mvtec30'\n",
    "classes_list = os.listdir(original_dataset_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train,validation,test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir,clss))\n",
    "    os.mkdir(os.path.join(validation_dir,clss))\n",
    "    os.mkdir(os.path.join(test_dir,clss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( leather_good ):  166\n",
      "Validation size( leather_good ):  55\n",
      "Test size( leather_good ):  55\n",
      "Train size( screw_anomaly ):  71\n",
      "Validation size( screw_anomaly ):  23\n",
      "Test size( screw_anomaly ):  23\n",
      "Train size( hazelnut_good ):  258\n",
      "Validation size( hazelnut_good ):  86\n",
      "Test size( hazelnut_good ):  86\n",
      "Train size( piil_anomaly ):  84\n",
      "Validation size( piil_anomaly ):  28\n",
      "Test size( piil_anomaly ):  28\n",
      "Train size( wood_good ):  159\n",
      "Validation size( wood_good ):  53\n",
      "Test size( wood_good ):  53\n",
      "Train size( toothbrush_good ):  43\n",
      "Validation size( toothbrush_good ):  14\n",
      "Test size( toothbrush_good ):  14\n",
      "Train size( metal_nut_good ):  145\n",
      "Validation size( metal_nut_good ):  48\n",
      "Test size( metal_nut_good ):  48\n",
      "Train size( transistor_anomaly ):  24\n",
      "Validation size( transistor_anomaly ):  8\n",
      "Test size( transistor_anomaly ):  8\n",
      "Train size( grid_anomaly ):  34\n",
      "Validation size( grid_anomaly ):  11\n",
      "Test size( grid_anomaly ):  11\n",
      "Train size( tile_good ):  157\n",
      "Validation size( tile_good ):  52\n",
      "Test size( tile_good ):  52\n",
      "Train size( carpet_anomaly ):  53\n",
      "Validation size( carpet_anomaly ):  17\n",
      "Test size( carpet_anomaly ):  17\n",
      "Train size( wood_anomaly ):  36\n",
      "Validation size( wood_anomaly ):  12\n",
      "Test size( wood_anomaly ):  12\n",
      "Train size( leather_anomaly ):  55\n",
      "Validation size( leather_anomaly ):  18\n",
      "Test size( leather_anomaly ):  18\n",
      "Train size( screw_good ):  216\n",
      "Validation size( screw_good ):  72\n",
      "Test size( screw_good ):  72\n",
      "Train size( hazelnut_anomaly ):  42\n",
      "Validation size( hazelnut_anomaly ):  14\n",
      "Test size( hazelnut_anomaly ):  14\n",
      "Train size( cable_anomaly ):  55\n",
      "Validation size( cable_anomaly ):  18\n",
      "Test size( cable_anomaly ):  18\n",
      "Train size( cable_good ):  169\n",
      "Validation size( cable_good ):  56\n",
      "Test size( cable_good ):  56\n",
      "Train size( tile_anomaly ):  50\n",
      "Validation size( tile_anomaly ):  16\n",
      "Test size( tile_anomaly ):  16\n",
      "Train size( zipper_anomaly ):  71\n",
      "Validation size( zipper_anomaly ):  23\n",
      "Test size( zipper_anomaly ):  23\n",
      "Train size( metal_nut_anomaly ):  55\n",
      "Validation size( metal_nut_anomaly ):  18\n",
      "Test size( metal_nut_anomaly ):  18\n",
      "Train size( zipper_good ):  163\n",
      "Validation size( zipper_good ):  54\n",
      "Test size( zipper_good ):  54\n",
      "Train size( capsule_good ):  145\n",
      "Validation size( capsule_good ):  48\n",
      "Test size( capsule_good ):  48\n",
      "Train size( carpet_good ):  184\n",
      "Validation size( carpet_good ):  61\n",
      "Test size( carpet_good ):  61\n",
      "Train size( pill_good ):  175\n",
      "Validation size( pill_good ):  58\n",
      "Test size( pill_good ):  58\n",
      "Train size( bottle_good ):  137\n",
      "Validation size( bottle_good ):  45\n",
      "Test size( bottle_good ):  45\n",
      "Train size( toothbrush_anomaly ):  18\n",
      "Validation size( toothbrush_anomaly ):  6\n",
      "Test size( toothbrush_anomaly ):  6\n",
      "Train size( grid_good ):  171\n",
      "Validation size( grid_good ):  57\n",
      "Test size( grid_good ):  57\n",
      "Train size( bottle_anomaly ):  37\n",
      "Validation size( bottle_anomaly ):  12\n",
      "Test size( bottle_anomaly ):  12\n",
      "Train size( transistor_good ):  163\n",
      "Validation size( transistor_good ):  54\n",
      "Test size( transistor_good ):  54\n",
      "Train size( capsule_anomaly ):  65\n",
      "Validation size( capsule_anomaly ):  21\n",
      "Test size( capsule_anomaly ):  21\n"
     ]
    }
   ],
   "source": [
    "# [데이터 분할과 클래스별 데이터 수 확인]\n",
    "\n",
    "import math\n",
    "\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir,clss)\n",
    "    fnames = os.listdir(path)\n",
    "        \n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(',clss,'): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print('Validation size(',clss,'): ', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir,clss),fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "    print('Test size(',clss,'): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss),fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3201\n",
      "1058\n",
      "1058\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/test')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 2\n",
    "\n",
    "original_dataset_dir = '/home/iai/Desktop/bsh/active_learning/data/mvtec2'\n",
    "classes_list = os.listdir(original_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train,validation,test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir,clss))\n",
    "    os.mkdir(os.path.join(validation_dir,clss))\n",
    "    os.mkdir(os.path.join(test_dir,clss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( good ):  2457\n",
      "Validation size( good ):  819\n",
      "Test size( good ):  819\n",
      "Train size( anomaly ):  754\n",
      "Validation size( anomaly ):  251\n",
      "Test size( anomaly ):  251\n"
     ]
    }
   ],
   "source": [
    "# [데이터 분할과 클래스별 데이터 수 확인]\n",
    "\n",
    "import math\n",
    "\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir,clss)\n",
    "    fnames = os.listdir(path)\n",
    "        \n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(',clss,'): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print('Validation size(',clss,'): ', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir,clss),fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "    print('Test size(',clss,'): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss),fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3211\n",
      "1070\n",
      "1070\n"
     ]
    }
   ],
   "source": [
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/test')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwanaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b1005dccb15e22d240b273f9fc181733100900e693183dab09dcac13af140a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
