{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 2 : Splitting Train/Val/Test/Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [데이터 분할을 위한 폴더 생성]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = '/home/iai/Desktop/bsh/active_learning/data/mvtec2_re'\n",
    "classes_list = os.listdir(original_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train,validation,test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir,clss))\n",
    "    os.mkdir(os.path.join(validation_dir,clss))\n",
    "    os.mkdir(os.path.join(test_dir,clss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( good ):  2457\n",
      "Validation size( good ):  819\n",
      "Test size( good ):  819\n",
      "Train size( anomaly ):  131\n",
      "Validation size( anomaly ):  43\n",
      "Test size( anomaly ):  43\n"
     ]
    }
   ],
   "source": [
    "# [데이터 분할과 클래스별 데이터 수 확인]\n",
    "\n",
    "import math\n",
    "\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir,clss)\n",
    "    fnames = os.listdir(path)\n",
    "        \n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(',clss,'): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print('Validation size(',clss,'): ', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir,clss),fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "    print('Test size(',clss,'): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss),fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2588\n",
      "862\n",
      "862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/anaconda3/envs/jwanaconda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/test')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 설정\n",
    "train_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/train'  # train dataset 폴더 경로\n",
    "initial_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/initial'  # initial dataset 폴더 경로\n",
    "initial_num = 100  # initial dataset으로 이동할 데이터 개수\n",
    "\n",
    "# 클래스 리스트\n",
    "class_list = os.listdir(train_dir)\n",
    "\n",
    "# train dataset에서 각 클래스별 데이터 개수 파악\n",
    "class_counts = {}\n",
    "total_count = 0\n",
    "for class_name in class_list:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    files = os.listdir(class_dir)\n",
    "    class_counts[class_name] = len(files)\n",
    "    total_count += class_counts[class_name]\n",
    "\n",
    "# 각 클래스별로 선택할 데이터 개수 설정\n",
    "initial_counts = {}\n",
    "initial_total = 0\n",
    "for class_name in class_list:\n",
    "    initial_counts[class_name] = round(initial_num * class_counts[class_name] / total_count)\n",
    "    initial_total += initial_counts[class_name]\n",
    "\n",
    "# 각 클래스별로 선택할 데이터 개수가 너무 적어서 부족한 경우 보충\n",
    "while initial_total < initial_num:\n",
    "    class_name = random.choice(class_list)\n",
    "    if initial_counts[class_name] < class_counts[class_name]:\n",
    "        initial_counts[class_name] += 1\n",
    "        initial_total += 1\n",
    "\n",
    "# train dataset에서 랜덤으로 initial dataset으로 이동할 데이터 선택\n",
    "initial_files = {}\n",
    "for class_name in class_list:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    files = os.listdir(class_dir)\n",
    "    files = [os.path.join(class_dir, file) for file in files]\n",
    "    initial_files[class_name] = random.sample(files, initial_counts[class_name])\n",
    "\n",
    "# 선택된 데이터를 initial dataset으로 이동\n",
    "for class_name, files in initial_files.items():\n",
    "    class_dest = os.path.join(initial_dir, class_name)\n",
    "    os.makedirs(class_dest, exist_ok=True)\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file)\n",
    "        dest_file = os.path.join(class_dest, file_name)\n",
    "        shutil.move(file, dest_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2488\n",
      "862\n",
      "862\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/test')\n",
    "initial_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec2/initial')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))\n",
    "print(len(initial_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 30 : Splitting Train/Val/Test/Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [데이터 분할을 위한 폴더 생성]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = '/home/iai/Desktop/bsh/active_learning/data/mvtec30_re'\n",
    "classes_list = os.listdir(original_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train,validation,test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir,clss))\n",
    "    os.mkdir(os.path.join(validation_dir,clss))\n",
    "    os.mkdir(os.path.join(test_dir,clss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( leather_good ):  166\n",
      "Validation size( leather_good ):  55\n",
      "Test size( leather_good ):  55\n",
      "Train size( screw_anomaly ):  11\n",
      "Validation size( screw_anomaly ):  3\n",
      "Test size( screw_anomaly ):  3\n",
      "Train size( hazelnut_good ):  258\n",
      "Validation size( hazelnut_good ):  86\n",
      "Test size( hazelnut_good ):  86\n",
      "Train size( wood_good ):  159\n",
      "Validation size( wood_good ):  53\n",
      "Test size( wood_good ):  53\n",
      "Train size( toothbrush_good ):  43\n",
      "Validation size( toothbrush_good ):  14\n",
      "Test size( toothbrush_good ):  14\n",
      "Train size( metal_nut_good ):  145\n",
      "Validation size( metal_nut_good ):  48\n",
      "Test size( metal_nut_good ):  48\n",
      "Train size( transistor_anomaly ):  8\n",
      "Validation size( transistor_anomaly ):  2\n",
      "Test size( transistor_anomaly ):  2\n",
      "Train size( grid_anomaly ):  9\n",
      "Validation size( grid_anomaly ):  3\n",
      "Test size( grid_anomaly ):  3\n",
      "Train size( tile_good ):  157\n",
      "Validation size( tile_good ):  52\n",
      "Test size( tile_good ):  52\n",
      "Train size( carpet_anomaly ):  9\n",
      "Validation size( carpet_anomaly ):  3\n",
      "Test size( carpet_anomaly ):  3\n",
      "Train size( wood_anomaly ):  8\n",
      "Validation size( wood_anomaly ):  2\n",
      "Test size( wood_anomaly ):  2\n",
      "Train size( leather_anomaly ):  9\n",
      "Validation size( leather_anomaly ):  3\n",
      "Test size( leather_anomaly ):  3\n",
      "Train size( screw_good ):  216\n",
      "Validation size( screw_good ):  72\n",
      "Test size( screw_good ):  72\n",
      "Train size( hazelnut_anomaly ):  14\n",
      "Validation size( hazelnut_anomaly ):  4\n",
      "Test size( hazelnut_anomaly ):  4\n",
      "Train size( cable_anomaly ):  9\n",
      "Validation size( cable_anomaly ):  3\n",
      "Test size( cable_anomaly ):  3\n",
      "Train size( cable_good ):  169\n",
      "Validation size( cable_good ):  56\n",
      "Test size( cable_good ):  56\n",
      "Train size( tile_anomaly ):  8\n",
      "Validation size( tile_anomaly ):  2\n",
      "Test size( tile_anomaly ):  2\n",
      "Train size( zipper_anomaly ):  9\n",
      "Validation size( zipper_anomaly ):  3\n",
      "Test size( zipper_anomaly ):  3\n",
      "Train size( pill_anomaly ):  9\n",
      "Validation size( pill_anomaly ):  3\n",
      "Test size( pill_anomaly ):  3\n",
      "Train size( metal_nut_anomaly ):  7\n",
      "Validation size( metal_nut_anomaly ):  2\n",
      "Test size( metal_nut_anomaly ):  2\n",
      "Train size( zipper_good ):  163\n",
      "Validation size( zipper_good ):  54\n",
      "Test size( zipper_good ):  54\n",
      "Train size( capsule_good ):  145\n",
      "Validation size( capsule_good ):  48\n",
      "Test size( capsule_good ):  48\n",
      "Train size( carpet_good ):  184\n",
      "Validation size( carpet_good ):  61\n",
      "Test size( carpet_good ):  61\n",
      "Train size( pill_good ):  175\n",
      "Validation size( pill_good ):  58\n",
      "Test size( pill_good ):  58\n",
      "Train size( bottle_good ):  137\n",
      "Validation size( bottle_good ):  45\n",
      "Test size( bottle_good ):  45\n",
      "Train size( toothbrush_anomaly ):  3\n",
      "Validation size( toothbrush_anomaly ):  1\n",
      "Test size( toothbrush_anomaly ):  1\n",
      "Train size( grid_good ):  171\n",
      "Validation size( grid_good ):  57\n",
      "Test size( grid_good ):  57\n",
      "Train size( bottle_anomaly ):  7\n",
      "Validation size( bottle_anomaly ):  2\n",
      "Test size( bottle_anomaly ):  2\n",
      "Train size( transistor_good ):  163\n",
      "Validation size( transistor_good ):  54\n",
      "Test size( transistor_good ):  54\n",
      "Train size( capsule_anomaly ):  7\n",
      "Validation size( capsule_anomaly ):  2\n",
      "Test size( capsule_anomaly ):  2\n"
     ]
    }
   ],
   "source": [
    "# [데이터 분할과 클래스별 데이터 수 확인]\n",
    "\n",
    "import math\n",
    "\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir,clss)\n",
    "    fnames = os.listdir(path)\n",
    "        \n",
    "    train_size = math.floor(len(fnames)*0.6)\n",
    "    validation_size = math.floor(len(fnames)*0.2)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(',clss,'): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print('Validation size(',clss,'): ', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir,clss),fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
    "    print('Test size(',clss,'): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss),fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2578\n",
      "851\n",
      "851\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/test')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 설정\n",
    "train_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/train'  # train dataset 폴더 경로\n",
    "initial_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/initial'  # initial dataset 폴더 경로\n",
    "initial_num = 100  # initial dataset으로 이동할 데이터 개수\n",
    "\n",
    "# 클래스 리스트\n",
    "class_list = os.listdir(train_dir)\n",
    "\n",
    "# train dataset에서 각 클래스별 데이터 개수 파악\n",
    "class_counts = {}\n",
    "total_count = 0\n",
    "for class_name in class_list:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    files = os.listdir(class_dir)\n",
    "    class_counts[class_name] = len(files)\n",
    "    total_count += class_counts[class_name]\n",
    "\n",
    "# 각 클래스별로 선택할 데이터 개수 설정\n",
    "initial_counts = {}\n",
    "initial_total = 0\n",
    "for class_name in class_list:\n",
    "    initial_counts[class_name] = round(initial_num * class_counts[class_name] / total_count)\n",
    "    initial_total += initial_counts[class_name]\n",
    "\n",
    "# 각 클래스별로 선택할 데이터 개수가 너무 적어서 부족한 경우 보충\n",
    "while initial_total < initial_num:\n",
    "    class_name = random.choice(class_list)\n",
    "    if initial_counts[class_name] < class_counts[class_name]:\n",
    "        initial_counts[class_name] += 1\n",
    "        initial_total += 1\n",
    "\n",
    "# train dataset에서 랜덤으로 initial dataset으로 이동할 데이터 선택\n",
    "initial_files = {}\n",
    "for class_name in class_list:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    files = os.listdir(class_dir)\n",
    "    files = [os.path.join(class_dir, file) for file in files]\n",
    "    initial_files[class_name] = random.sample(files, initial_counts[class_name])\n",
    "\n",
    "# 선택된 데이터를 initial dataset으로 이동\n",
    "for class_name, files in initial_files.items():\n",
    "    class_dest = os.path.join(initial_dir, class_name)\n",
    "    os.makedirs(class_dest, exist_ok=True)\n",
    "    for file in files:\n",
    "        file_name = os.path.basename(file)\n",
    "        dest_file = os.path.join(class_dest, file_name)\n",
    "        shutil.move(file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478\n",
      "851\n",
      "851\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/train')\n",
    "val_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/val')\n",
    "test_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/test')\n",
    "initial_dir = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec30/initial')\n",
    "\n",
    "\n",
    "print(len(train_dir))\n",
    "print(len(val_dir))\n",
    "print(len(test_dir))\n",
    "print(len(initial_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwanaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b1005dccb15e22d240b273f9fc181733100900e693183dab09dcac13af140a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
