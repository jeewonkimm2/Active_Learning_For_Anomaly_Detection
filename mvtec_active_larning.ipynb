{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( transistor_damaged_case ):  8\n",
      "Test size( transistor_damaged_case ):  2\n",
      "Train size( leather_good ):  221\n",
      "Test size( leather_good ):  55\n",
      "Train size( tile_gray_stroke ):  12\n",
      "Test size( tile_gray_stroke ):  3\n",
      "Train size( capsule_crack ):  18\n",
      "Test size( capsule_crack ):  4\n",
      "Train size( cable_missing_wire ):  8\n",
      "Test size( cable_missing_wire ):  2\n",
      "Train size( grid_bent ):  9\n",
      "Test size( grid_bent ):  2\n",
      "Train size( hazelnut_good ):  344\n",
      "Test size( hazelnut_good ):  86\n",
      "Train size( carpet_thread ):  15\n",
      "Test size( carpet_thread ):  3\n",
      "Train size( transistor_cut_lead ):  8\n",
      "Test size( transistor_cut_lead ):  2\n",
      "Train size( wood_hole ):  8\n",
      "Test size( wood_hole ):  2\n",
      "Train size( tile_crack ):  13\n",
      "Test size( tile_crack ):  3\n",
      "Train size( pill_contamination ):  16\n",
      "Test size( pill_contamination ):  4\n",
      "Train size( hazelnut_crack ):  14\n",
      "Test size( hazelnut_crack ):  3\n",
      "Train size( wood_good ):  212\n",
      "Test size( wood_good ):  53\n",
      "Train size( bottle_contamination ):  16\n",
      "Test size( bottle_contamination ):  4\n",
      "Train size( screw_scratch_neck ):  20\n",
      "Test size( screw_scratch_neck ):  5\n",
      "Train size( carpet_metal_contamination ):  13\n",
      "Test size( carpet_metal_contamination ):  3\n",
      "Train size( toothbrush_good ):  57\n",
      "Test size( toothbrush_good ):  14\n",
      "Train size( grid_glue ):  8\n",
      "Test size( grid_glue ):  2\n",
      "Train size( capsule_squeeze ):  16\n",
      "Test size( capsule_squeeze ):  4\n",
      "Train size( pill_color ):  20\n",
      "Test size( pill_color ):  5\n",
      "Train size( leather_poke ):  14\n",
      "Test size( leather_poke ):  3\n",
      "Train size( cable_poke_insulation ):  8\n",
      "Test size( cable_poke_insulation ):  2\n",
      "Train size( hazelnut_print ):  13\n",
      "Test size( hazelnut_print ):  3\n",
      "Train size( pill_pill_type ):  7\n",
      "Test size( pill_pill_type ):  1\n",
      "Train size( pill_combined ):  13\n",
      "Test size( pill_combined ):  3\n",
      "Train size( screw_scratch_head ):  19\n",
      "Test size( screw_scratch_head ):  4\n",
      "Train size( capsule_poke ):  16\n",
      "Test size( capsule_poke ):  4\n",
      "Train size( metal_nut_good ):  193\n",
      "Test size( metal_nut_good ):  48\n",
      "Train size( leather_cut ):  15\n",
      "Test size( leather_cut ):  3\n",
      "Train size( hazelnut_cut ):  13\n",
      "Test size( hazelnut_cut ):  3\n",
      "Train size( screw_manipulated_front ):  19\n",
      "Test size( screw_manipulated_front ):  4\n",
      "Train size( hazelnut_hole ):  14\n",
      "Test size( hazelnut_hole ):  3\n",
      "Train size( metal_nut_color ):  17\n",
      "Test size( metal_nut_color ):  4\n",
      "Train size( wood_combined ):  8\n",
      "Test size( wood_combined ):  2\n",
      "Train size( metal_nut_scratch ):  18\n",
      "Test size( metal_nut_scratch ):  4\n",
      "Train size( metal_nut_flip ):  18\n",
      "Test size( metal_nut_flip ):  4\n",
      "Train size( cable_bent_wire ):  10\n",
      "Test size( cable_bent_wire ):  2\n",
      "Train size( zipper_broken_teeth ):  15\n",
      "Test size( zipper_broken_teeth ):  3\n",
      "Train size( metal_nut_bent ):  20\n",
      "Test size( metal_nut_bent ):  5\n",
      "Train size( leather_color ):  15\n",
      "Test size( leather_color ):  3\n",
      "Train size( cable_cut_inner_insulation ):  11\n",
      "Test size( cable_cut_inner_insulation ):  2\n",
      "Train size( zipper_combined ):  12\n",
      "Test size( zipper_combined ):  3\n",
      "Train size( cable_combined ):  8\n",
      "Test size( cable_combined ):  2\n",
      "Train size( tile_rough ):  12\n",
      "Test size( tile_rough ):  3\n",
      "Train size( zipper_rough ):  13\n",
      "Test size( zipper_rough ):  3\n",
      "Train size( bottle_broken_large ):  16\n",
      "Test size( bottle_broken_large ):  4\n",
      "Train size( pill_faulty_imprint ):  15\n",
      "Test size( pill_faulty_imprint ):  3\n",
      "Train size( tile_good ):  210\n",
      "Test size( tile_good ):  52\n",
      "Train size( tile_glue_strip ):  14\n",
      "Test size( tile_glue_strip ):  3\n",
      "Train size( pill_crack ):  20\n",
      "Test size( pill_crack ):  5\n",
      "Train size( screw_good ):  288\n",
      "Test size( screw_good ):  72\n",
      "Train size( leather_fold ):  13\n",
      "Test size( leather_fold ):  3\n",
      "Train size( grid_thread ):  8\n",
      "Test size( grid_thread ):  2\n",
      "Train size( wood_color ):  6\n",
      "Test size( wood_color ):  1\n",
      "Train size( pill_scratch ):  19\n",
      "Test size( pill_scratch ):  4\n",
      "Train size( cable_good ):  225\n",
      "Test size( cable_good ):  56\n",
      "Train size( zipper_squeezed_teeth ):  12\n",
      "Test size( zipper_squeezed_teeth ):  3\n",
      "Train size( cable_missing_cable ):  9\n",
      "Test size( cable_missing_cable ):  2\n",
      "Train size( carpet_color ):  15\n",
      "Test size( carpet_color ):  3\n",
      "Train size( capsule_scratch ):  18\n",
      "Test size( capsule_scratch ):  4\n",
      "Train size( screw_thread_side ):  18\n",
      "Test size( screw_thread_side ):  4\n",
      "Train size( zipper_fabric_border ):  13\n",
      "Test size( zipper_fabric_border ):  3\n",
      "Train size( tile_oil ):  14\n",
      "Test size( tile_oil ):  3\n",
      "Train size( zipper_good ):  217\n",
      "Test size( zipper_good ):  54\n",
      "Train size( zipper_split_teeth ):  14\n",
      "Test size( zipper_split_teeth ):  3\n",
      "Train size( capsule_good ):  193\n",
      "Test size( capsule_good ):  48\n",
      "Train size( leather_glue ):  15\n",
      "Test size( leather_glue ):  3\n",
      "Train size( carpet_good ):  246\n",
      "Test size( carpet_good ):  61\n",
      "Train size( toothbrush_defective ):  24\n",
      "Test size( toothbrush_defective ):  6\n",
      "Train size( pill_good ):  234\n",
      "Test size( pill_good ):  58\n",
      "Train size( cable_cut_outer_insulation ):  8\n",
      "Test size( cable_cut_outer_insulation ):  2\n",
      "Train size( wood_liquid ):  8\n",
      "Test size( wood_liquid ):  2\n",
      "Train size( wood_scratch ):  16\n",
      "Test size( wood_scratch ):  4\n",
      "Train size( screw_thread_top ):  18\n",
      "Test size( screw_thread_top ):  4\n",
      "Train size( grid_broken ):  9\n",
      "Test size( grid_broken ):  2\n",
      "Train size( transistor_bent_lead ):  8\n",
      "Test size( transistor_bent_lead ):  2\n",
      "Train size( bottle_good ):  183\n",
      "Test size( bottle_good ):  45\n",
      "Train size( carpet_cut ):  13\n",
      "Test size( carpet_cut ):  3\n",
      "Train size( zipper_fabric_interior ):  12\n",
      "Test size( zipper_fabric_interior ):  3\n",
      "Train size( cable_cable_swap ):  9\n",
      "Test size( cable_cable_swap ):  2\n",
      "Train size( grid_good ):  228\n",
      "Test size( grid_good ):  57\n",
      "Train size( carpet_hole ):  13\n",
      "Test size( carpet_hole ):  3\n",
      "Train size( transistor_good ):  218\n",
      "Test size( transistor_good ):  54\n",
      "Train size( capsule_faulty_imprint ):  17\n",
      "Test size( capsule_faulty_imprint ):  4\n",
      "Train size( transistor_misplaced ):  8\n",
      "Test size( transistor_misplaced ):  2\n",
      "Train size( grid_metal_contamination ):  8\n",
      "Test size( grid_metal_contamination ):  2\n",
      "Train size( bottle_broken_small ):  17\n",
      "Test size( bottle_broken_small ):  4\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/mvtec88'\n",
    "classes_list = os.listdir(original_dataset_dir)\n",
    "\n",
    "base_dir = '/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/splitted'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train,validation,test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir,clss))\n",
    "    os.mkdir(os.path.join(test_dir,clss))\n",
    "    \n",
    "\n",
    "# [데이터 분할과 클래스별 데이터 수 확인]\n",
    "import math\n",
    "\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir,clss)\n",
    "    fnames = os.listdir(path)\n",
    "    \n",
    "    train_size = math.floor(len(fnames)*0.8)\n",
    "    test_size = math.floor(len(fnames)*0.2)\n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(',clss,'): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src,dst)\n",
    "        \n",
    "    test_fnames = fnames[train_size:(train_size+test_size)]\n",
    "    print('Test size(',clss,'): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss),fname)\n",
    "        shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/anaconda3/envs/jwanaconda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, SubsetRandomSampler, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms for dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/splitted/train', transform=transform)\n",
    "test_dataset = ImageFolder(root='/home/iai/Desktop/Jeewon/Study/Conference/Active_Learning/data/splitted/test', transform=transform)\n",
    "\n",
    "# Define initial labeled dataset\n",
    "num_initial_samples = 1000\n",
    "labeled_indices = torch.randperm(len(train_dataset))[:num_initial_samples]\n",
    "labeled_dataset = torch.utils.data.Subset(train_dataset, labeled_indices)\n",
    "\n",
    "# Define unlabeled dataset\n",
    "unlabeled_indices = torch.arange(len(train_dataset))[~torch.eq(torch.arange(len(train_dataset)).unsqueeze(1), labeled_indices).any(1)]\n",
    "unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "# Define data loaders\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=32, shuffle=True)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Define ResNet model\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=88):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18.conv1(x)\n",
    "        x = self.resnet18.bn1(x)\n",
    "        x = self.resnet18.relu(x)\n",
    "        x = self.resnet18.maxpool(x)\n",
    "\n",
    "        x = self.resnet18.layer1(x)\n",
    "        x = self.resnet18.layer2(x)\n",
    "        x = self.resnet18.layer3(x)\n",
    "        x = self.resnet18.layer4(x)\n",
    "\n",
    "        x = self.resnet18.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = ResNet18(num_classes=88).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, optimizer, labeled_loader):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    total = 0\n",
    "    for images, labels in labeled_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        train_acc += (predicted == labels).sum().item()\n",
    "    train_loss /= len(labeled_loader)\n",
    "    train_acc /= total\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query number: 1\n",
      "Train Loss: 1.9573, Train Accuracy: 0.6830\n",
      "Test Loss: 4.2235, Test Accuracy: 0.1620\n",
      "Query number: 2\n",
      "Train Loss: 1.2845, Train Accuracy: 0.7432\n",
      "Test Loss: 4.6284, Test Accuracy: 0.1302\n",
      "Query number: 3\n",
      "Train Loss: 1.1977, Train Accuracy: 0.7491\n",
      "Test Loss: 4.6069, Test Accuracy: 0.1504\n",
      "Query number: 4\n",
      "Train Loss: 1.1094, Train Accuracy: 0.7600\n",
      "Test Loss: 4.6941, Test Accuracy: 0.1755\n",
      "Query number: 5\n",
      "Train Loss: 1.1173, Train Accuracy: 0.7535\n",
      "Test Loss: 4.8147, Test Accuracy: 0.1553\n",
      "Query number: 6\n",
      "Train Loss: 1.0713, Train Accuracy: 0.7552\n",
      "Test Loss: 4.8853, Test Accuracy: 0.1553\n",
      "Query number: 7\n",
      "Train Loss: 0.9972, Train Accuracy: 0.7617\n",
      "Test Loss: 5.0944, Test Accuracy: 0.1446\n",
      "Query number: 8\n",
      "Train Loss: 0.9525, Train Accuracy: 0.7786\n",
      "Test Loss: 4.7690, Test Accuracy: 0.1688\n",
      "Query number: 9\n",
      "Train Loss: 1.0485, Train Accuracy: 0.7516\n",
      "Test Loss: 4.9597, Test Accuracy: 0.1553\n",
      "Query number: 10\n",
      "Train Loss: 1.0366, Train Accuracy: 0.7547\n",
      "Test Loss: 5.1657, Test Accuracy: 0.1649\n"
     ]
    }
   ],
   "source": [
    "# Active learning loop\n",
    "num_queries = 10\n",
    "batch_size = 32\n",
    "\n",
    "for query in range(num_queries):\n",
    "    print(\"Query number:\", query+1)\n",
    "    \n",
    "    # Train model on labeled dataset\n",
    "    train_loss, train_acc = train(model, optimizer, labeled_loader)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Evaluate model on test dataset\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            test_acc += (predicted == labels).sum().item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= total\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Make model predictions on unlabeled dataset\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in unlabeled_loader:\n",
    "            images = images.to(device)  # Move data to GPU\n",
    "            output = model(images)\n",
    "            predictions.append(output)\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "\n",
    "    # Select samples to label using entropy-based method\n",
    "    entropy = -torch.sum(torch.softmax(predictions, dim=1) * torch.log(torch.softmax(predictions, dim=1)), dim=1)\n",
    "    _, idx = torch.topk(entropy, k=batch_size)\n",
    "    labeled_indices = torch.cat([labeled_indices, unlabeled_indices[idx]])\n",
    "    unlabeled_indices = unlabeled_indices[~torch.eq(unlabeled_indices.unsqueeze(1), unlabeled_indices[idx]).any(1)]\n",
    "    \n",
    "    # Update labeled and unlabeled datasets\n",
    "    labeled_dataset = torch.utils.data.Subset(train_dataset, labeled_indices)\n",
    "    unlabeled_dataset = torch.utils.data.Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "    # Update labeled and unlabeled data loaders\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwanaconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91b1005dccb15e22d240b273f9fc181733100900e693183dab09dcac13af140a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
